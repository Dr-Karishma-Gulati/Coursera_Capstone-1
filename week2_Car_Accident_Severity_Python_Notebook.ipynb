{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project - Car Accident Severity (Week 2) \n",
    "## Python Notebook - Data Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* [Introduction: Business Problem](#introduction)\n",
    "* [Data](#data)\n",
    "* [Methodology](#methodology)\n",
    "* [Exploratory Data Analysis](#e)\n",
    "* [Modeling, Testing and Evaluation](#m)\n",
    "* [Results and Discussion](#r)\n",
    "* [Conclusion and Outlook](#c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: Business Problem <a name=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Road traffic injuries (RTIs) are a major public health problem. The annual global status reports on\n",
    "road safety, launched by the World Health Organization (WHO), highlights that the number of\n",
    "road traffic deaths has exceeded one million in recent years. \n",
    "\n",
    "The analytical data mining\n",
    "solutions can be largely employed to determine and predict related influential factors and thus\n",
    "to explain RTIs severity. \n",
    "\n",
    "The objective of this project is to predict the car accident severity by training and evaluating\n",
    "supervised machine learning algorithms. \n",
    "\n",
    "The report of this project can be targeted to stakeholders, who are involved with road traffic\n",
    "injuries incl. road administrators, traffic control authorities, and emergency road services in order\n",
    "to help them predict the car accident severities and improve the road users' safety margins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data <a name=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given dataset used in this project is provided by the SDOT Traffic Management Division, Traffic Records Group,\n",
    "timeframe: 2004 to present, Seattle, United States. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first load required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O Data-Collisions.csv https://s3.us.cloud-object-storage.appdomain.cloud/cf-courses-data/CognitiveClass/DP0701EN/version-2/Data-Collisions.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data From CSV File  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data-Collisions.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how unbalanced the dataset is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.SEVERITYCODE.value_counts().plot(kind='bar')\n",
    "plt.xlabel('Severity Code (1: prop damage, 2:injury)') \n",
    "plt.ylabel('Number of Accidents') \n",
    "plt.title('Accident Severity (imbalanced)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Getting the number of missing values in each column\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df.SEVERITYCODE==1]\n",
    "df_minority = df[df.SEVERITYCODE==2]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=136485,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Display new class counts\n",
    "df_upsampled.SEVERITYCODE.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how balanced the dataset using oversmapling looks.\n",
    "df_upsampled.SEVERITYCODE.value_counts().plot(kind='bar')\n",
    "plt.xlabel('Severity Code (1: prop damage, 2:injury)') \n",
    "plt.ylabel('Number of Accidents') \n",
    "plt.title('Accident Severity (balanced)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rename X and Y with Longitude and Latitude \n",
    "df1 = df.rename(columns={'X': 'LONGITUDE', 'Y': 'LATITUDE'})\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop LOCATION; Langitude and Latitude used instead.\n",
    "# Two copies of SEVERITYCODE exist, drop the second SEVERITYCODE.1\n",
    "#Drop columns incluidng codes: OBJECTID, INCKEY, COLDETKEY, REPORTNO,INTKEY,EXCEPTRSNCODE, SDOT_COLCODE, SDOTCOLNUM --->\n",
    "#ST_COLCODE, ST_COLDESC, SEGLANEKEY, CROSSWALKKEY \n",
    "#Drop redundant infos: STATUS, EXCEPTRSNDESC, INCDATE , INCDTTM, SDOT_COLDESC, PEDROWNOTGRNT,ST_COLDESC, UNDERINFL--->\n",
    "#PEDCYLCOUNT, HITPARKEDCAR, SEVERITYDESC, ADDRTYPE  \n",
    "df2 = df1.drop([\"LOCATION\", \"SEVERITYCODE.1\", \"OBJECTID\", \"INCKEY\", \"COLDETKEY\", \"REPORTNO\", \"INTKEY\", \n",
    "          \"EXCEPTRSNCODE\", \"SDOT_COLCODE\", \"ST_COLCODE\", \"SEGLANEKEY\", \"CROSSWALKKEY\", \"SDOTCOLNUM\", \n",
    "          \"STATUS\", \"EXCEPTRSNDESC\", \"INCDATE\", \"INCDTTM\", \"SDOT_COLDESC\", \"PEDROWNOTGRNT\", \"UNDERINFL\", \n",
    "        \"PEDCYLCOUNT\", \"HITPARKEDCAR\", \"ST_COLDESC\", \"SEVERITYDESC\", \"ADDRTYPE\", \"COLLISIONTYPE\", \"PEDCOUNT\"], axis=1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the type of each column\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the shape of the data frame\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the name of each column\n",
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Returning the objects containing counts of unique values\n",
    "df2['WEATHER'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling of missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing NaN value by Unknown\n",
    "df2['WEATHER'].replace(np.NaN, \"Unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Unknown and Other by Clear, the most frequent value of the column\n",
    "encoding_WEATHER = {\"WEATHER\": \n",
    "                            {\"Clear\": 1,\n",
    "                             \"Unknown\": 1,\n",
    "                             \"Other\": 1,\n",
    "                             \"Raining\": 2,\n",
    "                             \"Overcast\": 3,\n",
    "                             \"Snowing\": 4,\n",
    "                             \"Fog/Smog/Smoke\": 5,\n",
    "                             \"Sleet/Hail/Freezing Rain\": 6,\n",
    "                             \"Blowing Sand/Dirt\": 7,\n",
    "                             \"Severe Crosswind\": 8,\n",
    "                             \"Partly Cloudy\": 9}}\n",
    "df2.replace(encoding_WEATHER, inplace=True)\n",
    "df2['WEATHER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['SPEEDING'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing NaN value by N\n",
    "df2['SPEEDING'].replace(np.NaN, \"N\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_SPEEDING = {\"SPEEDING\": \n",
    "                            {\"Y\": 1,\n",
    "                             \"N\": 0,\n",
    "                              }}\n",
    "df2.replace(encoding_SPEEDING, inplace=True)\n",
    "df2['SPEEDING'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['LIGHTCOND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing NaN value by Unknown\n",
    "df2['LIGHTCOND'].replace(np.NaN, \"Unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Unknown and Other by Daylight, the most frequent value of the column\n",
    "encoding_LIGHTCOND = {\"LIGHTCOND\": \n",
    "                            {\"Daylight\": 0,\n",
    "                             \"Unknown\": 0,\n",
    "                             \"Other\": 0,\n",
    "                             \"Dark - Street Lights On\": 1,\n",
    "                             \"Dusk\": 1,\n",
    "                             \"Dawn\": 1,\n",
    "                             \"Dark - No Street Lights\": 1,\n",
    "                             \"Dark - Street Lights Off\": 1,\n",
    "                             \"Dark - Unknown Lighting\": 1,\n",
    "                              }}\n",
    "df2.replace(encoding_LIGHTCOND, inplace=True)\n",
    "df2['LIGHTCOND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['ROADCOND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing NaN value by Unknown\n",
    "df2['ROADCOND'].replace(np.NaN, \"Unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Unknown and Other by Dry, the most frequent value of the column\n",
    "encoding_ROADCOND = {\"ROADCOND\": \n",
    "                            {\"Dry\": 1,\n",
    "                             \"Unknown\": 1,\n",
    "                             \"Other\": 1,\n",
    "                             \"Wet\": 2,\n",
    "                             \"Ice\": 3,\n",
    "                             \"Snow/Slush\": 4,\n",
    "                             \"Standing Water\": 5,\n",
    "                             \"Sand/Mud/Dirt\": 6,\n",
    "                             \"Oil\": 7,\n",
    "                              }}\n",
    "df2.replace(encoding_ROADCOND, inplace=True)\n",
    "df2['ROADCOND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['JUNCTIONTYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing NaN value by Unknown\n",
    "df2['JUNCTIONTYPE'].replace(np.NaN, \"Unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Unknown by Mid-Block (not related to intersection), the most frequent value of the column\n",
    "encoding_JUNCTIONTYPE = {\"JUNCTIONTYPE\": \n",
    "                            {\"Mid-Block (not related to intersection)\": 1,\n",
    "                             \"Unknown\": 1,\n",
    "                             \"At Intersection (intersection related)\": 2,\n",
    "                             \"Mid-Block (but intersection related)\": 3,\n",
    "                             \"Driveway Junction\": 4,\n",
    "                             \"At Intersection (but not related to intersection)\": 5,\n",
    "                             \"Ramp Junction\": 6,\n",
    "                              }}\n",
    "df2.replace(encoding_JUNCTIONTYPE, inplace=True)\n",
    "df2['JUNCTIONTYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['LONGITUDE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN values are placed by the mean values of the column\n",
    "avg_LONGITUDE = df2[\"LONGITUDE\"].astype(\"float\").mean(axis=0)\n",
    "print(\"Average of LONGITUDE:\", avg_LONGITUDE)\n",
    "df2['LONGITUDE'].replace(np.NaN, avg_LONGITUDE, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['LATITUDE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN values are placed by the mean values of the column\n",
    "avg_LATITUDE = df2[\"LATITUDE\"].astype(\"float\").mean(axis=0)\n",
    "print(\"Average of LATITUDE:\", avg_LATITUDE)\n",
    "df2['LATITUDE'].replace(np.NaN, avg_LATITUDE, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:prop damage   2:injury\n",
    "df2['SEVERITYCODE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['INATTENTIONIND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing NaN value by N\n",
    "df2['INATTENTIONIND'].replace(np.NaN, \"N\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_INATTENTIONIND = {\"INATTENTIONIND\": \n",
    "                            {\"Y\": 1,\n",
    "                             \"N\": 0,\n",
    "                              }}\n",
    "df2.replace(encoding_INATTENTIONIND, inplace=True)\n",
    "df2['SPEEDING'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tabulating the first five rows\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology<a name=\"methodology\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the features are selected, they are employed for an explanatory data analysis to figure out more about their effects. The focus is on identifying the feature\n",
    "conditions that have a bigger effect on the severity which leads to injuries. To do so, the dataset is\n",
    "filtered further and the corresponding values of features are sorted.\n",
    "\n",
    "In the next step, the features are processed for predictive modeling analysis. 4 machine learning models are created using the classification techniques as listed below:\n",
    "\n",
    "* K-Nearest Neighbors (KNN)\n",
    "* Decision Tree\n",
    "* Logistic Regression\n",
    "* Random Forest\n",
    "\n",
    "The created models are tested and then evaluated based on their accuracy score to find the more accurate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis <a name=\"e\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The map with markers of the accident locations in Seattle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing Folium Package for mapping\n",
    "!conda install -c conda-forge folium=0.5.0 --yes\n",
    "import folium\n",
    "\n",
    "print('Folium installed and imported!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing 300 data points on the map\n",
    "limit = 300\n",
    "df_m1 = df2[[\"LATITUDE\", \"LONGITUDE\"]]\n",
    "df_m2 = df_m1.iloc[0:limit, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instantiate a feature group for the incidents in the dataframe\n",
    "\n",
    "Seattle_map = folium.Map(location=[47.6062, -122.3321], zoom_start=12)\n",
    "\n",
    "incidents = folium.map.FeatureGroup()\n",
    "\n",
    "# loop through the 300 points and add each to the incidents feature group\n",
    "for lat, lng, in zip(df_m2.LATITUDE, df_m2.LONGITUDE):\n",
    "    incidents.add_child(\n",
    "        folium.features.CircleMarker(\n",
    "            [lat, lng],\n",
    "            radius=5, # define how big you want the circle markers to be\n",
    "            color='yellow',\n",
    "            fill=True,\n",
    "            fill_color='blue',\n",
    "            fill_opacity=0.6\n",
    "        )\n",
    "    )\n",
    "\n",
    "# add incidents to map\n",
    "Seattle_map.add_child(incidents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Selecting the severity code of 2 i.e. with injuries and making  another data frame for this purpose\n",
    "Sev_2 = df2.loc[df2['SEVERITYCODE']==2]\n",
    "Sev_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between the weather conditions and the accident severity with injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Sev_2_w = Sev_2['WEATHER'].value_counts()\n",
    "Sev_2_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'Clear', 'Raining', 'Overcast', 'Other'\n",
    "sizes = [37856, 11176, 8745, sum(Sev_2_w[3:9])]\n",
    "explode = (0.1,0, 0, 0)\n",
    "fig1, ax1 = plt.subplots(figsize=(15,7))\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.title('Effect of Weather Conditions on the Severity with Injury', y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between the person count and the accident severity with injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sev_2_p = Sev_2['PERSONCOUNT'].value_counts()\n",
    "Sev_2_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 2, 3, 4, 1, 5, 0, 6, '>6'\n",
    "sizes = [27811, 13461, 6295, 3296, 2969, 1762, 1357, sum(Sev_2_p[3:9])]\n",
    "explode = (0.1, 0, 0, 0, 0, 0, 0, 0)\n",
    "fig1, ax1 = plt.subplots(figsize=(15,7))\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.title('Effect of Person count on the Severity with Injury', y=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between the vehicle count and the accident severity with injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Sev_2_v = Sev_2['VEHCOUNT'].value_counts()\n",
    "Sev_2_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 2, 1, 3, 0, 4,'>4'\n",
    "sizes = [35949, 14105, 5470, 1227, 1078, sum(Sev_2_p[5:12])]\n",
    "explode = (0.1, 0, 0, 0, 0, 0)\n",
    "fig1, ax1 = plt.subplots(figsize=(15,9))\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.title('Effect of Vehicle count on the Severity with Injury', y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between the junction type and the accident severity with injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sev_2_j = Sev_2['JUNCTIONTYPE'].value_counts()\n",
    "Sev_2_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'At Iintersection_intersection related', 'Mid-Block_not intersection related', 'Mid-Block with intersection', 'Driveway Junction', 'Other'\n",
    "sizes = [27174, 19806, 7297, 3234, sum(Sev_2_j[4:6])]\n",
    "explode = (0.1, 0, 0, 0, 0)\n",
    "fig1, ax1 = plt.subplots(figsize=(15,9))\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.title('Effect of Junction type on the Severity with Injury', y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between the inattention and the accident severity with injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sev_2_i = Sev_2['INATTENTIONIND'].value_counts()\n",
    "Sev_2_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'No', 'Yes'\n",
    "sizes = [47791, 10397]\n",
    "explode = (0.1, 0)\n",
    "fig1, ax1 = plt.subplots(figsize=(15,7))\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.title('Effect of Inattention on the Severity with Injury', y=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between the road conditions and the accident severity with injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sev_2_r = Sev_2['ROADCOND'].value_counts()\n",
    "Sev_2_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'dry', 'wet', 'ic, sand, oil, standing water'\n",
    "sizes = [41916, 15755, sum(Sev_2_r[2:7])]\n",
    "explode = (0.1, 0, 0)\n",
    "fig1, ax1 = plt.subplots(figsize=(15,7))\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.title('Effect of Road condition on the Severity with Injury', y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between the light conditions and the accident severity with injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sev_2_l = Severity_2['LIGHTCOND'].value_counts()\n",
    "Sev_2_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'day light', 'dark'\n",
    "sizes = [40291, 17897]\n",
    "explode = (0.1, 0)\n",
    "fig1, ax1 = plt.subplots(figsize=(15,7))\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.title('Effect of Light condition on the Severity with Injury', y=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between the speeding and the accident severity with injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sev_2_s = Severity_2['SPEEDING'].value_counts()\n",
    "Sev_2_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'No', 'Yes'\n",
    "sizes = [54657, 3531]\n",
    "explode = (0.1, 0)\n",
    "fig1, ax1 = plt.subplots(figsize=(15,7))\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.title('Effect of Speeding condition on the Severity with Injury', y=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling, Testing and Evaluation <a name=\"m\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a new data frame\n",
    "Feature = df2[['LONGITUDE', 'LATITUDE', 'PERSONCOUNT', 'VEHCOUNT',\n",
    "       'JUNCTIONTYPE', 'INATTENTIONIND', 'WEATHER', 'ROADCOND', 'LIGHTCOND',\n",
    "       'SPEEDING']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2['SEVERITYCODE'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Splitting the data into train-test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the best k\n",
    "Ks = 10\n",
    "mean_acc = np.zeros((Ks-1))\n",
    "std_acc = np.zeros((Ks-1))\n",
    "ConfustionMx = [];\n",
    "for n in range(1,Ks):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    kNNeigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n",
    "    yhat = kNNeigh.predict(X_test)\n",
    "    \n",
    "    \n",
    "    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat);\n",
    "    \n",
    "    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n",
    "\n",
    "mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot model accuracy for Different number of Neighbors\n",
    "plt.plot(range(1,Ks),mean_acc,'g')\n",
    "plt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\n",
    "plt.legend(('Accuracy ', '+/- 3xstd'))\n",
    "plt.ylabel('Accuracy ')\n",
    "plt.xlabel('Number of Nabors (K)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Best k =\", mean_acc.argmax()+1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the model using the best k \n",
    "k=8\n",
    "kNNeigh= KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\n",
    "kNNeigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evalaution\n",
    "print(\"K-Nearest Neighbours Accuray: \", metrics.accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling\n",
    "DTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n",
    "DTree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Prediction\n",
    "yhat = DTree.predict(X_test)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evalaution\n",
    "print(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling\n",
    "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n",
    "LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "yhat = LR.predict(X_test)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evalaution\n",
    "print(\"Logistic Regresion's Accuracy: \", metrics.accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "yhat =clf.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evalaution\n",
    "print(\"Random Forest's Accuracy: \", metrics.accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize important features using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a list of feature names\n",
    "feat_labels = ['SEVERITYCODE', 'LONGITUDE', 'LATITUDE','PERSONCOUNT', \n",
    "               'VEHCOUNT', 'JUNCTIONTYPE', 'INATTENTIONIND',\n",
    "               'WEATHER', 'ROADCOND', 'LIGHTCOND', 'SPEEDING']\n",
    "# Set the target for the prediction\n",
    "target='SEVERITYCODE'\n",
    "\n",
    "# Create arrays for the features and the response variable\n",
    "\n",
    "# set X and y\n",
    "y = df2[target]\n",
    "X = df2.drop(target, axis=1)\n",
    "\n",
    "# Split the data set into training and testing data sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)\n",
    "\n",
    "# Create a random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "feature_imp = pd.Series(clf.feature_importances_,index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "# Creating a bar plot, displaying only the top k features\n",
    "k=10\n",
    "sns.barplot(x=feature_imp[:10], y=feature_imp.index[:k])\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Discussion <a name=\"r\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the accuracy score versus algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "algo_lst =['K-Nearest Neighbors','Decision Trees','Logistic Regression','Random Forest']\n",
    "\n",
    "accuracy_lst = [0.7267753948889174, 0.7429562090663927, 0.7030949017593425, 0.711878772312829]\n",
    "\n",
    "# Generate a list of ticks for y-axis\n",
    "y_ticks=np.arange(len(algo_lst))\n",
    "\n",
    "#Combine the list of algorithms and list of accuracy scores into a dataframe, sort the value based on accuracy score\n",
    "df_acc=pd.DataFrame(list(zip(algo_lst, accuracy_lst)), columns=['Algorithm','Accuracy_Score']).sort_values(by=['Accuracy_Score'],ascending = True)\n",
    "\n",
    "# Make a plot\n",
    "ax=df_acc.plot.barh('Algorithm', 'Accuracy_Score', align='center',legend=False,color='0.5')\n",
    "\n",
    "# Add the data label on to the plot\n",
    "for i in ax.patches:\n",
    "    # get_width pulls left or right; get_y pushes up or down\n",
    "    ax.text(i.get_width()+0.02, i.get_y()+0.2, str(round(i.get_width(),2)), fontsize=10)\n",
    "\n",
    "# Set the limit, lables, ticks and title\n",
    "plt.xlim(0,1.1)\n",
    "plt.xlabel('Accuracy Score')\n",
    "plt.yticks(y_ticks, df_acc['Algorithm'], rotation=0)\n",
    "plt.title('Accuracy Score versus Algorithm')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the score of accuracies obtained by the algorithms K-Nearest Neighbors, Decision Tree, Logistic Regression, and Random Forest, the decision tree has been proved to give better accuracy. \n",
    "\n",
    "During the modeling with the K-Nearest Neighbors classifier, it was observed that the computer required much more time.  But it took less time to execute the decision tree modeling. This can also represent better effectiveness and compatibility of the decision tree for handling this given dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Outlook <a name=\"c\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this study, supervised machine learning is employed to predict car accident severity. The imbalanced dataset is firstly balanced, and the raw data is understood and prepared in different steps to be used for the predictive modeling analysis. In parallel, an explanatory data analysis is done to gain more insight into the relationship between the features and the severity of the accidents.\n",
    "\n",
    "Four machine learning algorithms (K-Nearest Neighbors, Decision Trees, Logistic Regression, and Random Forest) are applied in which the decision tree has shown better compatibility with the dataset, resulting in higher accuracy (0.74).\n",
    "\n",
    "One idea for future work can be developing the decision tree machine learning model to improve its accuracy further. Adding more data to the dataset can help to compensate for the missing values. Gathering more data about other parameters such as the age of the drivers can also help to gain a more detailed insight into the car accident severity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
